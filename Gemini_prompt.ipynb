{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe168d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai\n",
    "from google.genai import types\n",
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "import time\n",
    "\n",
    "from pydantic import BaseModel\n",
    "from typing import List\n",
    "\n",
    "# --- 1. 配置 Gemini ---\n",
    "# 从环境变量中读取API密钥并配置\n",
    "try:\n",
    "    client = genai.Client()\n",
    "except KeyError:\n",
    "    print(\"错误：请先设置 GOOGLE_API_KEY 环境变量。\")\n",
    "    exit()\n",
    "\n",
    "# --- 辅助函数 (与之前基本相同) ---\n",
    "\n",
    "def load_data(json_path, accurate_text_path):\n",
    "    \"\"\"加载JSON时间戳数据和精确的文本文件\"\"\"\n",
    "    try:\n",
    "        with open(json_path, 'r', encoding='utf-8') as f:\n",
    "            timing_data = json.load(f)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"错误: JSON文件未找到 at {json_path}\")\n",
    "        return None, None\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"错误: JSON文件格式不正确 at {json_path}\")\n",
    "        return None, None\n",
    "    try:\n",
    "        with open(accurate_text_path, 'r', encoding='utf-8') as f:\n",
    "            accurate_text = f.read()\n",
    "    except FileNotFoundError:\n",
    "        print(f\"错误: 精确文本文件未找到 at {accurate_text_path}\")\n",
    "        return None, None\n",
    "    return timing_data, accurate_text\n",
    "\n",
    "def format_timing_data_for_prompt(segments_batch):\n",
    "    lines = []\n",
    "    for seg in segments_batch:\n",
    "        lines.append(f'  - 时间: {seg[\"start\"]:.3f} - {seg[\"end\"]:.3f}, 文本: \"{seg[\"text\"]}\"')\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "class SubtitleSegment(BaseModel):\n",
    "    start: float\n",
    "    end: float\n",
    "    original_text: str\n",
    "    translated_text: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a463e0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# ------------ 配置 ------------\n",
    "BATCH_SIZE            = 50\n",
    "MODEL_FOR_CHUNKING    = \"gemini-2.5-flash-lite\"   # 用于提取片段的小模型\n",
    "MODEL_FOR_ALIGNMENT   = \"gemini-2.5-pro\"        # 用于对齐+翻译的大模型\n",
    "\n",
    "# 文本定位（切分）——提示词完全保留\n",
    "CHUNK_SYSTEM_PROMPT = (\n",
    "    \"\"\"\n",
    "        你是一个精通中文和日文的双语内容定位专家。\n",
    "        你的唯一任务是：根据一段“参考中文文本”的含义，在一部“完整日文文本”中，找到并提取出与之语义完全对应的原始日文片段。\n",
    "\n",
    "        # 你的工作流程：\n",
    "        1.  **理解中文**：仔细阅读并完全理解“参考中文文本”所表达的核心意思。\n",
    "        2.  **定位日文**：在“完整日文文本”中地毯式搜索，找到与中文含义完全匹配的日文句子或段落。\n",
    "        3.  **精确提取**：完整地提取出你找到的那部分日文原文。为了保证上下文的连贯性，你可以适度地包含前后相邻的几个词或语句，切记只能多不能遗漏。\n",
    "        4.  **纯净输出**：你的输出**必须**是纯粹的、未经修改的日文文本，除非原文有乱码非日文字符。**绝对不要**包含任何解释、标题、标签、引号或任何非日文内容。\n",
    "\n",
    "        ---\n",
    "        【一个完整的处理范例】\n",
    "        [完整日文文本]:\n",
    "        ...失礼します。ちょっとインタビューさせていただきたいなと思います。はい、夏目響です。デビューして何年目ぐらいですか？5周年になりましたので6年目です。いろんな役が演じてきて、セックス感も変わってきたんじゃないですか...\n",
    "\n",
    "        [参考中文文本]:\n",
    "        是的，我是夏目响。你出道几年了？因为已经5周年了，所以是第6年。\n",
    "\n",
    "        [输出]:\n",
    "        はい、夏目響です。デビューして何年目ぐらいですか？5周年になりましたので6年目です。\n",
    "        ---\n",
    "\n",
    "        现在，请严格遵循以上规则和范例，处理下面的实际任务。\n",
    "    \"\"\")\n",
    "\n",
    "chunk_config = types.GenerateContentConfig(\n",
    "    system_instruction=CHUNK_SYSTEM_PROMPT,\n",
    "    temperature=0.0,\n",
    ")\n",
    "\n",
    "# 对齐+翻译——提示词完全保留\n",
    "ALIGN_SYSTEM_PROMPT = \"\"\"\n",
    "你是一个专业的字幕制作和翻译专家。你的任务是根据两份日文转录本，完成一个精确的、带时间戳的中文翻译。\n",
    "一份是“带时间戳的不精确转录本”，它提供了准确的时间信息但文本内容可能有误。\n",
    "另一份是“精确转录本”，它提供了准确的文本内容但没有时间信息。\n",
    "你的工作流程如下：\n",
    "1.  **对齐**：以“带时间戳的不精确转录本”为基础框架，将“精确转录本”中的文本内容，智能地填充到对应的时间段（segment）中。注意，两者的句子和词语不一定完全匹配，但是大部分是match的，尤其是一个segment里的第一个假名和最后一个假名，这是你匹配的重要参考，千万不能错配，你需要根据语义和上下文进行最佳的对齐，确保最终的文本流畅且符合逻辑，最重要的是，精细文本与粗文本的时间戳是一致的。\n",
    "2.  **翻译**：将对齐好的、精确的日文文本内容，逐段翻译成流畅、自然的简体中文。\n",
    "3.  **输出**：必须以一个JSON数组的格式返回结果，请把最终数组放入 JSON 对象的 `segments` 字段，仅返回该对象。不包含任何额外的解释。每个JSON对象包含以下字段：'start', 'end', 'original_text', 'translated_text'。\n",
    "备注：\n",
    "有时精确转录本中可能出现一些语气词在粗转录本中没有的情况，或者相反，这种情况下，忽略这些语气词，只对齐粗转录本中存在的内容。\n",
    "\"\"\"\n",
    "\n",
    "align_config = types.GenerateContentConfig(\n",
    "    system_instruction=ALIGN_SYSTEM_PROMPT,\n",
    "    temperature=0.1,\n",
    "    response_schema=list[SubtitleSegment],\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "def extract_relevant_chunk_with_gemini(full_text, segment_batch):\n",
    "    reference_text = \" \".join([s[\"text\"] for s in segment_batch])\n",
    "    contents = (\n",
    "        f\"这是“完整文本”：\\n---\\n{full_text}\\n---\\n\\n\"\n",
    "        f\"请提取与下列“参考文本”对应的部分：\\n---\\n{reference_text}\\n---\"\n",
    "    )\n",
    "    try:\n",
    "        rsp = client.models.generate_content(\n",
    "            model=MODEL_FOR_CHUNKING,\n",
    "            contents=contents,\n",
    "            config=chunk_config\n",
    "        )\n",
    "        return rsp.text.strip()\n",
    "    except Exception as e:\n",
    "        print(f\"Gemini 定位失败: {e}\")\n",
    "        return None\n",
    "\n",
    "def align_and_translate_with_gemini(segment_batch, accurate_text_chunk):\n",
    "    formatted_timings = segment_batch\n",
    "    contents = f\"\"\"\n",
    "--- 带时间戳的不精确转录本 (当前批次) ---\n",
    "{formatted_timings}\n",
    "---------------------------------\n",
    "\n",
    "--- 精确转录本 (相关片段) ---\n",
    "{accurate_text_chunk}\n",
    "-------------------\n",
    "\"\"\"\n",
    "    try:\n",
    "        rsp = client.models.generate_content(\n",
    "            model=MODEL_FOR_ALIGNMENT,\n",
    "            contents=contents,\n",
    "            config=align_config\n",
    "        )\n",
    "        obj = json.loads(rsp.text)\n",
    "        print(obj)\n",
    "        if isinstance(obj, dict) and \"segments\" in obj:\n",
    "            return obj[\"segments\"]\n",
    "        if isinstance(obj, list):\n",
    "            return obj\n",
    "        for v in obj.values():\n",
    "            if isinstance(v, list):\n",
    "                return v\n",
    "    except Exception as e:\n",
    "        print(f\"Gemini 对齐/翻译失败: {e}\")\n",
    "        return None\n",
    "\n",
    "def format_time_for_srt(sec):\n",
    "    if sec is None or not isinstance(sec, (int, float)):\n",
    "        sec = 0.0\n",
    "    h, rem = divmod(sec, 3600)\n",
    "    m, s = divmod(rem, 60)\n",
    "    ms = int((s - int(s)) * 1000)\n",
    "    return f\"{int(h):02}:{int(m):02}:{int(s):02},{ms:03}\"\n",
    "\n",
    "def to_srt(all_segments):\n",
    "    lines = []\n",
    "    for i, item in enumerate(all_segments, 1):\n",
    "        if not {\"start\",\"end\",\"translated_text\"} <= item.keys():\n",
    "            print(f\"警告: 第{i}条缺字段，已跳过\")\n",
    "            continue\n",
    "        lines += [\n",
    "            str(i),\n",
    "            f\"{format_time_for_srt(item['start'])} --> {format_time_for_srt(item['end'])}\",\n",
    "            item[\"translated_text\"],\n",
    "            \"\"\n",
    "        ]\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "# ------------- 主流程 -------------\n",
    "def main():\n",
    "    json_file     = \n",
    "    accurate_file = \n",
    "    output_srt    = \n",
    "\n",
    "    timing_data, accurate_text = load_data(json_file, accurate_file)\n",
    "\n",
    "    if not (timing_data and accurate_text):\n",
    "        return\n",
    "\n",
    "    segments = timing_data.get(\"segments\", [])\n",
    "    if not segments:\n",
    "        print(\"segments 为空\")\n",
    "        return\n",
    "\n",
    "    total_batches = (len(segments) + BATCH_SIZE - 1) // BATCH_SIZE\n",
    "    all_results   = []\n",
    "\n",
    "    for batch_idx in range(total_batches):\n",
    "        batch = segments[batch_idx * BATCH_SIZE : (batch_idx + 1) * BATCH_SIZE]\n",
    "        if not batch:\n",
    "            continue\n",
    "        print(f\"\\n=== 处理批次 {batch_idx + 1}/{total_batches} ===\")\n",
    "\n",
    "        # A. 提取精确文本片段\n",
    "\n",
    "        chunk = extract_relevant_chunk_with_gemini(accurate_text, batch)\n",
    "        if not chunk:\n",
    "            print(\"  无法提取精确文本，跳过此批次\")\n",
    "            continue\n",
    "\n",
    "        # B. 对齐 + 翻译\n",
    "        timing_prompt = format_timing_data_for_prompt(batch)\n",
    "        result = align_and_translate_with_gemini(timing_prompt, chunk)\n",
    "        if result:\n",
    "            all_results.extend(result)\n",
    "            print(f\"  成功获得 {len(result)} 条字幕\")\n",
    "        else:\n",
    "            print(\"  对齐/翻译失败\")\n",
    "\n",
    "        time.sleep(1)  # 轻微延时减小速率限制风险\n",
    "\n",
    "    if all_results:\n",
    "        Path(output_srt).write_text(to_srt(all_results), encoding=\"utf-8\")\n",
    "        print(f\"\\n✅ SRT 已生成：{output_srt}\")\n",
    "    else:\n",
    "        print(\"\\n❌ 未获取到任何字幕\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "subworkflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
